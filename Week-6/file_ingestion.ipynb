{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import modin.pandas as mpd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Ensure required backends for Modin and Dask are initialized\n",
    "try:\n",
    "    import ray\n",
    "    ray.init()  # Initialize Ray for Modin\n",
    "\n",
    "    from dask.distributed import Client\n",
    "    client = Client()  # Start Dask client\n",
    "except Exception as e:\n",
    "    print(f\"Initialization error for Modin/Dask backends: {e}\")\n",
    "\n",
    "# File paths\n",
    "file_path = '/Users/vaweng02/Desktop/Combined_Flights_2021.csv'\n",
    "yaml_path = 'file.yaml'\n",
    "output_path = 'output_file.csv.gz'\n",
    "\n",
    "# Function to validate YAML schema\n",
    "def validate_yaml_schema(yaml_file):\n",
    "    try:\n",
    "        with open(yaml_file, 'r') as f:\n",
    "            schema = yaml.safe_load(f)\n",
    "            print(\"YAML schema loaded successfully.\")\n",
    "            return schema\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: YAML schema file not found.\")\n",
    "        return None\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error reading YAML file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to load a CSV file\n",
    "def load_csv(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found at path: {file_path}\")\n",
    "    print(\"Loading dataset...\")\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Function to clean column names\n",
    "def clean_column_names(df):\n",
    "    print(\"Cleaning column names...\")\n",
    "    df.columns = df.columns.str.replace('[^a-zA-Z0-9]+', '_', regex=True)\n",
    "    return df\n",
    "\n",
    "# Function to process dataframe\n",
    "def process_dataframe(df, subset_columns):\n",
    "    print(\"Processing dataframe...\")\n",
    "    if not all(col in df.columns for col in subset_columns):\n",
    "        raise ValueError(\"One or more subset columns are not present in the dataframe.\")\n",
    "    subset_df = df[subset_columns]\n",
    "    return subset_df\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    try:\n",
    "        # Load and validate YAML schema\n",
    "        schema = validate_yaml_schema(yaml_path)\n",
    "        if schema is None:\n",
    "            print(\"Skipping YAML validation.\")\n",
    "\n",
    "        # Load dataset\n",
    "        df = load_csv(file_path)\n",
    "\n",
    "        # Clean column names\n",
    "        df = clean_column_names(df)\n",
    "\n",
    "        # Columns to subset (customize as needed)\n",
    "        subset_columns = ['Column1', 'Column2', 'Column3']  # Replace with actual column names\n",
    "\n",
    "        # Process dataframe\n",
    "        subset_df = process_dataframe(df, subset_columns)\n",
    "\n",
    "        # Save processed data to compressed file\n",
    "        print(\"Saving processed data to compressed file...\")\n",
    "        subset_df.to_csv(output_path, sep='|', compression='gzip', index=False)\n",
    "        print(f\"Processed data saved to: {output_path}\")\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(fnf_error)\n",
    "    except ValueError as val_error:\n",
    "        print(val_error)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    print(f\"Execution time: {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
